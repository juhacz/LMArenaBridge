# api_server.py
# Backend nowej generacji LMArena Bridge

import asyncio
import json
import logging
import os
import sys
import subprocess
import time
import uuid
import re
import threading
import random
import mimetypes
from datetime import datetime
from contextlib import asynccontextmanager

import uvicorn
import requests
from packaging.version import parse as parse_version
from fastapi import FastAPI, WebSocket, WebSocketDisconnect, Request, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse, JSONResponse, Response

# --- Importy moduÅ‚Ã³w wewnÄ™trznych ---
from modules.file_uploader import upload_to_file_bed


# --- Podstawowa konfiguracja ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# --- Globalny stan i konfiguracja ---
CONFIG = {}  # Przechowuje konfiguracjÄ™ zaÅ‚adowanÄ… z config.jsonc
# browser_ws przechowuje poÅ‚Ä…czenie WebSocket z pojedynczym skryptem Tampermonkey.
# Uwaga: obecna architektura zakÅ‚ada, Å¼e tylko jedna karta przeglÄ…darki jest aktywna.
# Aby obsÅ‚uÅ¼yÄ‡ wiele kart, trzeba by rozszerzyÄ‡ to do zarzÄ…dzania wieloma poÅ‚Ä…czeniami.
browser_ws: WebSocket | None = None
# response_channels przechowuje kolejki odpowiedzi dla kaÅ¼dego Å¼Ä…dania API.
# Klucz to request_id, wartoÅ›Ä‡ to asyncio.Queue.
response_channels: dict[str, asyncio.Queue] = {}
last_activity_time = None  # Rejestruje czas ostatniej aktywnoÅ›ci
idle_monitor_thread = None  # WÄ…tek monitorujÄ…cy bezczynnoÅ›Ä‡
main_event_loop = None  # GÅ‚Ã³wna pÄ™tla zdarzeÅ„
# Nowe: Å›ledzi, czy trwa odÅ›wieÅ¼anie zwiÄ…zane z weryfikacjÄ… Cloudflare
IS_REFRESHING_FOR_VERIFICATION = False


# --- Mapowanie modeli ---
# MODEL_NAME_TO_ID_MAP przechowuje teraz bogatsze obiekty: { "model_name": {"id": "...", "type": "..."} }
MODEL_NAME_TO_ID_MAP = {}
MODEL_ENDPOINT_MAP = {}  # Nowe: przechowuje mapowania modeli do session/message ID
DEFAULT_MODEL_ID = None  # DomyÅ›lne ID modelu: None

def load_model_endpoint_map():
    """Wczytuje mapowanie modeli -> endpointÃ³w z model_endpoint_map.json."""
    global MODEL_ENDPOINT_MAP
    try:
        with open('model_endpoint_map.json', 'r', encoding='utf-8') as f:
            content = f.read()
            # Pozwalamy na pusty plik
            if not content.strip():
                MODEL_ENDPOINT_MAP = {}
            else:
                MODEL_ENDPOINT_MAP = json.loads(content)
        logger.info(f"PomyÅ›lnie wczytano {len(MODEL_ENDPOINT_MAP)} mapowaÅ„ endpointÃ³w z 'model_endpoint_map.json'.")
    except FileNotFoundError:
        logger.warning("Plik 'model_endpoint_map.json' nie zostaÅ‚ znaleziony. UÅ¼ywana bÄ™dzie pusta mapa.")
        MODEL_ENDPOINT_MAP = {}
    except json.JSONDecodeError as e:
        logger.error(f"BÅ‚Ä…d podczas Å‚adowania/parowania 'model_endpoint_map.json': {e}. UÅ¼ywana bÄ™dzie pusta mapa.")
        MODEL_ENDPOINT_MAP = {}

def _parse_jsonc(jsonc_string: str) -> dict:
    """
    Solidne parsowanie JSONC, usuwanie komentarzy.
    """
    lines = jsonc_string.splitlines()
    no_comments_lines = []
    in_block_comment = False
    for line in lines:
        stripped_line = line.strip()
        if in_block_comment:
            if '*/' in stripped_line:
                in_block_comment = False
                line = stripped_line.split('*/', 1)[1]
            else:
                continue
        
        if '/*' in line and not in_block_comment:
            before_comment, _, after_comment = line.partition('/*')
            if '*/' in after_comment:
                _, _, after_block = after_comment.partition('*/')
                line = before_comment + after_block
            else:
                line = before_comment
                in_block_comment = True

        if line.strip().startswith('//'):
            continue
        
        no_comments_lines.append(line)

    return json.loads("\n".join(no_comments_lines))

def load_config():
    """Wczytuje konfiguracjÄ™ z config.jsonc i obsÅ‚uguje komentarze JSONC."""
    global CONFIG
    try:
        with open('config.jsonc', 'r', encoding='utf-8') as f:
            content = f.read()
        CONFIG = _parse_jsonc(content)
        logger.info("PomyÅ›lnie wczytano konfiguracjÄ™ z 'config.jsonc'.")
        # Logowanie kluczowych ustawieÅ„
        logger.info(f"  - Tryb Tavern: {'âœ… WÅ‚Ä…czony' if CONFIG.get('tavern_mode_enabled') else 'âŒ WyÅ‚Ä…czony'}")
        logger.info(f"  - Tryb Bypass: {'âœ… WÅ‚Ä…czony' if CONFIG.get('bypass_enabled') else 'âŒ WyÅ‚Ä…czony'}")
    except (FileNotFoundError, json.JSONDecodeError) as e:
        logger.error(f"BÅ‚Ä…d podczas Å‚adowania/parowania 'config.jsonc': {e}. UÅ¼ywana bÄ™dzie domyÅ›lna konfiguracja.")
        CONFIG = {}

def load_model_map():
    """Wczytuje mapowanie modeli z models.json, obsÅ‚uguje format 'id:type'."""
    global MODEL_NAME_TO_ID_MAP
    try:
        with open('models.json', 'r', encoding='utf-8') as f:
            raw_map = json.load(f)
            
        processed_map = {}
        for name, value in raw_map.items():
            if isinstance(value, str) and ':' in value:
                parts = value.split(':', 1)
                model_id = parts[0] if parts[0].lower() != 'null' else None
                model_type = parts[1]
                processed_map[name] = {"id": model_id, "type": model_type}
            else:
                # ObsÅ‚uga formatu domyÅ›lnego / starszego
                processed_map[name] = {"id": value, "type": "text"}

        MODEL_NAME_TO_ID_MAP = processed_map
        logger.info(f"PomyÅ›lnie wczytano i sparsowano {len(MODEL_NAME_TO_ID_MAP)} modeli z 'models.json'.")

    except (FileNotFoundError, json.JSONDecodeError) as e:
        logger.error(f"BÅ‚Ä…d podczas Å‚adowania 'models.json': {e}. Lista modeli bÄ™dzie pusta.")
        MODEL_NAME_TO_ID_MAP = {}

# --- ObsÅ‚uga ogÅ‚oszeÅ„ ---
def check_and_display_announcement():
    """Sprawdza i wyÅ›wietla jednorazowe ogÅ‚oszenie."""
    announcement_file = "announcement-lmarena.json"
    if os.path.exists(announcement_file):
        try:
            logger.info("="*60)
            logger.info("ðŸ“¢ Wykryto aktualizacjÄ™ z ogÅ‚oszeniem, treÅ›Ä‡:")
            with open(announcement_file, 'r', encoding='utf-8') as f:
                announcement = json.load(f)
                title = announcement.get("title", "OgÅ‚oszenie")
                content = announcement.get("content", [])
                
                logger.info(f"   --- {title} ---")
                for line in content:
                    logger.info(f"   {line}")
                logger.info("="*60)

        except json.JSONDecodeError:
            logger.error(f"Nie moÅ¼na sparsowaÄ‡ pliku ogÅ‚oszenia '{announcement_file}'. ZawartoÅ›Ä‡ moÅ¼e nie byÄ‡ poprawnym JSON.")
        except Exception as e:
            logger.error(f"BÅ‚Ä…d podczas odczytu pliku ogÅ‚oszenia: {e}")
        finally:
            try:
                os.remove(announcement_file)
                logger.info(f"Plik ogÅ‚oszenia '{announcement_file}' zostaÅ‚ usuniÄ™ty.")
            except OSError as e:
                logger.error(f"Nie udaÅ‚o siÄ™ usunÄ…Ä‡ pliku ogÅ‚oszenia '{announcement_file}': {e}")

# --- Sprawdzanie aktualizacji ---
GITHUB_REPO = "Lianues/LMArenaBridge"

def download_and_extract_update(version):
    """Pobiera i rozpakowuje najnowszÄ… wersjÄ™ do folderu tymczasowego."""
    update_dir = "update_temp"
    if not os.path.exists(update_dir):
        os.makedirs(update_dir)

    try:
        zip_url = f"https://github.com/{GITHUB_REPO}/archive/refs/heads/main.zip"
        logger.info(f"Pobieram nowÄ… wersjÄ™ z {zip_url}...")
        response = requests.get(zip_url, timeout=60)
        response.raise_for_status()

        # Potrzebne importy zipfile i io
        import zipfile
        import io
        with zipfile.ZipFile(io.BytesIO(response.content)) as z:
            z.extractall(update_dir)
        
        logger.info(f"Nowa wersja zostaÅ‚a pobrana i rozpakowana do '{update_dir}'.")
        return True
    except requests.RequestException as e:
        logger.error(f"BÅ‚Ä…d pobierania aktualizacji: {e}")
    except zipfile.BadZipFile:
        logger.error("Pobrany plik nie jest poprawnym archiwum zip.")
    except Exception as e:
        logger.error(f"Nieznany bÅ‚Ä…d podczas rozpakowywania aktualizacji: {e}")
    
    return False

def check_for_updates():
    """Sprawdza GitHub pod kÄ…tem nowej wersji."""
    if not CONFIG.get("enable_auto_update", True):
        logger.info("Automatyczne aktualizacje sÄ… wyÅ‚Ä…czone â€” pomijam sprawdzenie.")
        return

    current_version = CONFIG.get("version", "0.0.0")
    logger.info(f"Aktualna wersja: {current_version}. Sprawdzam aktualizacje na GitHub...")

    try:
        config_url = f"https://raw.githubusercontent.com/{GITHUB_REPO}/main/config.jsonc"
        response = requests.get(config_url, timeout=10)
        response.raise_for_status()

        jsonc_content = response.text
        remote_config = _parse_jsonc(jsonc_content)
        
        remote_version_str = remote_config.get("version")
        if not remote_version_str:
            logger.warning("W zdalnym pliku konfiguracyjnym nie znaleziono numeru wersji â€” pomijam sprawdzenie.")
            return

        if parse_version(remote_version_str) > parse_version(current_version):
            logger.info("="*60)
            logger.info(f"ðŸŽ‰ Znaleziono nowÄ… wersjÄ™! ðŸŽ‰")
            logger.info(f"  - Obecna: {current_version}")
            logger.info(f"  - Najnowsza: {remote_version_str}")
            if download_and_extract_update(remote_version_str):
                logger.info("PrzygotowujÄ™ aplikacjÄ™ do aktualizacji. Serwer wyÅ‚Ä…czy siÄ™ i uruchomi skrypt aktualizujÄ…cy za 5 sekund.")
                time.sleep(5)
                update_script_path = os.path.join("modules", "update_script.py")
                # Uruchamiamy niezaleÅ¼ny proces Popen
                subprocess.Popen([sys.executable, update_script_path])
                # Eleganckie zakoÅ„czenie bieÅ¼Ä…cego procesu
                os._exit(0)
            else:
                logger.error(f"Automatyczna aktualizacja nie powiodÅ‚a siÄ™. Pobierz rÄ™cznie: https://github.com/{GITHUB_REPO}/releases/latest")
            logger.info("="*60)
        else:
            logger.info("Program jest aktualny.")

    except requests.RequestException as e:
        logger.error(f"BÅ‚Ä…d podczas sprawdzania aktualizacji: {e}")
    except json.JSONDecodeError:
        logger.error("BÅ‚Ä…d parsowania zdalnego pliku konfiguracyjnego.")
    except Exception as e:
        logger.error(f"Nieznany bÅ‚Ä…d podczas sprawdzania aktualizacji: {e}")

# --- Aktualizacja listy modeli ---
def extract_models_from_html(html_content):
    """
    WyodrÄ™bnia peÅ‚ne obiekty JSON modeli z zawartoÅ›ci HTML, uÅ¼ywajÄ…c dopasowania nawiasÃ³w
    aby zapewniÄ‡ kompletnoÅ›Ä‡ obiektu.
    """
    models = []
    model_names = set()
    
    # Szukamy potencjalnych pozycji poczÄ…tku obiektu JSON modelu
    for start_match in re.finditer(r'\{\\"id\\":\\"[a-f0-9-]+\\"', html_content):
        start_index = start_match.start()
        
        # Dopasowywanie nawiasÃ³w od pozycji startowej
        open_braces = 0
        end_index = -1
        
        # Optymalizacja: ustaw limit wyszukiwania, by uniknÄ…Ä‡ nieskoÅ„czonych pÄ™tli
        search_limit = start_index + 10000  # zakÅ‚adamy, Å¼e definicja modelu nie przekroczy 10000 znakÃ³w
        
        for i in range(start_index, min(len(html_content), search_limit)):
            if html_content[i] == '{':
                open_braces += 1
            elif html_content[i] == '}':
                open_braces -= 1
                if open_braces == 0:
                    end_index = i + 1
                    break
        
        if end_index != -1:
            # WyciÄ…gamy kompletny, escape'owany JSON
            json_string_escaped = html_content[start_index:end_index]
            
            # Usuwamy escape'y
            json_string = json_string_escaped.replace('\\"', '"').replace('\\\\', '\\')
            
            try:
                model_data = json.loads(json_string)
                model_name = model_data.get('publicName')
                
                # UnikalnoÅ›Ä‡ wedÅ‚ug publicName
                if model_name and model_name not in model_names:
                    models.append(model_data)
                    model_names.add(model_name)
            except json.JSONDecodeError as e:
                logger.warning(f"BÅ‚Ä…d parsowania wyodrÄ™bnionego obiektu JSON: {e} - fragment: {json_string[:150]}...")
                continue

    if models:
        logger.info(f"PomyÅ›lnie wyodrÄ™bniono i sparsowano {len(models)} modeli.")
        return models
    else:
        logger.error("BÅ‚Ä…d: nie znaleziono Å¼adnych kompletnych obiektÃ³w JSON reprezentujÄ…cych modele w odpowiedzi HTML.")
        return None

def save_available_models(new_models_list, models_path="available_models.json"):
    """
    Zapisuje wyodrÄ™bnionÄ… listÄ™ obiektÃ³w modeli do pliku JSON.
    """
    logger.info(f"Wykryto {len(new_models_list)} modeli, aktualizujÄ™ '{models_path}'...")
    
    try:
        with open(models_path, 'w', encoding='utf-8') as f:
            # Zapisujemy bezpoÅ›rednio listÄ™ obiektÃ³w modeli
            json.dump(new_models_list, f, indent=4, ensure_ascii=False)
        logger.info(f"âœ… Plik '{models_path}' zostaÅ‚ zaktualizowany i zawiera {len(new_models_list)} modeli.")
    except IOError as e:
        logger.error(f"BÅ‚Ä…d podczas zapisu pliku '{models_path}': {e}")

# --- Logika automatycznego restartu ---
def restart_server():
    """Powiadamia klienta o odÅ›wieÅ¼eniu, a nastÄ™pnie restartuje serwer."""
    logger.warning("="*60)
    logger.warning("Wykryto dÅ‚ugi czas bezczynnoÅ›ci serwera â€” przygotowujÄ™ restart...")
    logger.warning("="*60)
    
    # 1. (asynchronicznie) powiadom przeglÄ…darkÄ™ o odÅ›wieÅ¼eniu
    async def notify_browser_refresh():
        if browser_ws:
            try:
                # WysyÅ‚amy polecenie 'reconnect' aby poinformowaÄ‡ frontend, Å¼e to planowany restart
                await browser_ws.send_text(json.dumps({"command": "reconnect"}, ensure_ascii=False))
                logger.info("WysÅ‚ano do przeglÄ…darki polecenie 'reconnect'.")
            except Exception as e:
                logger.error(f"BÅ‚Ä…d wysyÅ‚ania polecenia 'reconnect': {e}")
    
    # Uruchamiamy asynchronicznÄ… funkcjÄ™ w gÅ‚Ã³wnej pÄ™tli zdarzeÅ„
    if browser_ws and browser_ws.client_state.name == 'CONNECTED' and main_event_loop:
        asyncio.run_coroutine_threadsafe(notify_browser_refresh(), main_event_loop)
    
    # 2. KrÃ³tkie opÃ³Åºnienie, aby upewniÄ‡ siÄ™, Å¼e wiadomoÅ›Ä‡ dotarÅ‚a
    time.sleep(3)
    
    # 3. Wykonanie restartu
    logger.info("RestartujÄ™ serwer...")
    os.execv(sys.executable, ['python'] + sys.argv)

def idle_monitor():
    """Uruchamiane w tle â€” monitoruje bezczynnoÅ›Ä‡ serwera."""
    global last_activity_time
    
    # Czekamy, aÅ¼ last_activity_time zostanie ustawione po starcie
    while last_activity_time is None:
        time.sleep(1)
        
    logger.info("WÄ…tek monitorujÄ…cy bezczynnoÅ›Ä‡ uruchomiony.")
    
    while True:
        if CONFIG.get("enable_idle_restart", False):
            timeout = CONFIG.get("idle_restart_timeout_seconds", 300)
            
            # JeÅ›li timeout == -1, wyÅ‚Ä…czamy restart
            if timeout == -1:
                time.sleep(10)  # pauza, aby uniknÄ…Ä‡ gorÄ…cej pÄ™tli
                continue

            idle_time = (datetime.now() - last_activity_time).total_seconds()
            
            if idle_time > timeout:
                logger.info(f"Serwer byÅ‚ bezczynny przez {idle_time:.0f}s, przekroczono prÃ³g {timeout}s.")
                restart_server()
                break  # koÅ„czymy, proces zostanie zastÄ…piony
                
        # Sprawdzamy co 10 sekund
        time.sleep(10)

# --- FastAPI lifecycle ---
@asynccontextmanager
async def lifespan(app: FastAPI):
    """Funkcja wykonywana przy starcie serwera."""
    global idle_monitor_thread, last_activity_time, main_event_loop
    main_event_loop = asyncio.get_running_loop()  # Pobieramy gÅ‚Ã³wnÄ… pÄ™tlÄ™ zdarzeÅ„
    load_config()  # Najpierw wczytujemy konfiguracjÄ™
    
    # --- Wypisanie aktualnego trybu dziaÅ‚ania ---
    mode = CONFIG.get("id_updater_last_mode", "direct_chat")
    target = CONFIG.get("id_updater_battle_target", "A")
    logger.info("="*60)
    logger.info(f"  Aktualny tryb operacyjny: {mode.upper()}")
    if mode == 'battle':
        logger.info(f"  - Tryb Battle, cel: Asystent {target}")
    logger.info("  (Tryb moÅ¼na zmieniÄ‡ uruchamiajÄ…c id_updater.py)")
    logger.info("="*60)

    check_for_updates()  # SprawdÅº aktualizacje
    load_model_map()  # Wczytaj mapÄ™ modeli
    load_model_endpoint_map()  # Wczytaj mapowanie endpointÃ³w modeli
    logger.info("Serwer uruchomiony. Oczekiwanie na poÅ‚Ä…czenie skryptu Tampermonkey...")

    # WyÅ›wietl ogÅ‚oszenie na koniec, Å¼eby byÅ‚o bardziej widoczne
    check_and_display_announcement()

    # Ustawiamy czas ostatniej aktywnoÅ›ci po wczytaniu modeli
    last_activity_time = datetime.now()
    
    # Uruchamiamy wÄ…tek monitorujÄ…cy bezczynnoÅ›Ä‡, jeÅ›li skonfigurowano
    if CONFIG.get("enable_idle_restart", False):
        idle_monitor_thread = threading.Thread(target=idle_monitor, daemon=True)
        idle_monitor_thread.start()
        

    yield
    logger.info("Serwer siÄ™ zamyka.")

app = FastAPI(lifespan=lifespan)

# --- Konfiguracja middleware CORS ---
# Dopuszczamy wszystkie ÅºrÃ³dÅ‚a, metody i nagÅ‚Ã³wki â€” bezpieczne dla narzÄ™dzi lokalnych.
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# --- Funkcje pomocnicze ---
def save_config():
    """Zapisuje obecny obiekt CONFIG z powrotem do config.jsonc, starajÄ…c siÄ™ zachowaÄ‡ komentarze."""
    try:
        # Wczytujemy oryginalny plik, Å¼eby zachowaÄ‡ komentarze
        with open('config.jsonc', 'r', encoding='utf-8') as f:
            lines = f.readlines()

        # Bezpieczne zastÄ™powanie wartoÅ›ci za pomocÄ… wyraÅ¼eÅ„ regularnych
        def replacer(key, value, content):
            # Regex znajdzie klucz i dopasuje jego wartoÅ›Ä‡ do przecinka lub zamkniÄ™cia obiektu
            pattern = re.compile(rf'("{key}"\s*:\s*").*?("?)(,?\s*)$', re.MULTILINE)
            replacement = rf'\g<1>{value}\g<2>\g<3>'
            if not pattern.search(content):  # JeÅ›li klucz nie istnieje, dodajemy go na koÅ„cu (prostsze podejÅ›cie)
                 content = re.sub(r'}\s*$', f'  ,"{key}": "{value}"\n}}', content)
            else:
                 content = pattern.sub(replacement, content)
            return content

        content_str = "".join(lines)
        content_str = replacer("session_id", CONFIG["session_id"], content_str)
        content_str = replacer("message_id", CONFIG["message_id"], content_str)
        
        with open('config.jsonc', 'w', encoding='utf-8') as f:
            f.write(content_str)
        logger.info("âœ… PomyÅ›lnie zaktualizowano informacje o sesji w config.jsonc.")
    except Exception as e:
        logger.error(f"âŒ BÅ‚Ä…d zapisu do config.jsonc: {e}", exc_info=True)


async def _process_openai_message(message: dict) -> dict:
    """
    Przetwarza wiadomoÅ›Ä‡ w formacie OpenAI, rozdzielajÄ…c tekst i zaÅ‚Ä…czniki.
    - Rozbija multimodalne czÄ™Å›ci na czysty tekst i listÄ™ zaÅ‚Ä…cznikÃ³w.
    - Logika 'file bed' zostaÅ‚a przeniesiona do preprocesora chat_completions; tutaj tylko budujemy zaÅ‚Ä…czniki.
    - Zapewnia, Å¼e pusta treÅ›Ä‡ roli 'user' zostanie zastÄ…piona spacjÄ…, aby uniknÄ…Ä‡ bÅ‚Ä™dÃ³w po stronie LMArena.
    """
    content = message.get("content")
    role = message.get("role")
    attachments = []
    text_content = ""

    if isinstance(content, list):
        text_parts = []
        for part in content:
            if part.get("type") == "text":
                text_parts.append(part.get("text", ""))
            elif part.get("type") == "image_url":
                # URL moÅ¼e byÄ‡ base64 lub HTTP (juÅ¼ zastÄ…piony przez preprocesor)
                image_url_data = part.get("image_url", {})
                url = image_url_data.get("url")
                original_filename = image_url_data.get("detail")

                try:
                    # Dla base64 trzeba wyciÄ…gnÄ…Ä‡ content_type
                    if url.startswith("data:"):
                        content_type = url.split(';')[0].split(':')[1]
                    else:
                        # Dla HTTP prÃ³bujemy zgadnÄ…Ä‡ typ MIME
                        content_type = mimetypes.guess_type(url)[0] or 'application/octet-stream'

                    # Na podstawie content_type wybieramy prefiks i rozszerzenie
                    if not original_filename:
                        # Prefiks na podstawie typu gÅ‚Ã³wnego
                        main_type = content_type.split('/')[0] if '/' in content_type else 'file'
                        prefix = main_type if main_type in ['image', 'audio', 'video', 'application', 'text'] else 'file'
                        
                        # UÅ¼ywamy mimetypes do uzyskania rozszerzenia
                        ext = mimetypes.guess_extension(content_type)
                        if ext:
                            ext = ext.lstrip('.')
                        else:
                            # JeÅ›li nie uda siÄ™ rozpoznaÄ‡, uÅ¼ywamy 'bin'
                            ext = 'bin'
                        
                        file_name = f"{prefix}_{uuid.uuid4()}.{ext}"
                    else:
                        file_name = original_filename
                    
                    attachments.append({
                        "name": file_name,
                        "contentType": content_type,
                        "url": url
                    })

                except (AttributeError, IndexError, ValueError) as e:
                    logger.warning(f"BÅ‚Ä…d podczas przetwarzania URL zaÅ‚Ä…cznika: {url[:100]}... BÅ‚Ä…d: {e}")

        text_content = "\n\n".join(text_parts)
    elif isinstance(content, str):
        text_content = content

    if role == "user" and not text_content.strip():
        text_content = " "

    return {
        "role": role,
        "content": text_content,
        "attachments": attachments
    }

async def convert_openai_to_lmarena_payload(openai_data: dict, session_id: str, message_id: str, mode_override: str = None, battle_target_override: str = None) -> dict:
    """
    Konwertuje ciaÅ‚o Å¼Ä…dania OpenAI na uproszczony Å‚adunek wymagany przez skrypt Tampermonkey,
    stosuje tryb Tavern, tryb Bypass oraz tryb battle.
    Dodatkowo obsÅ‚uguje nadpisanie trybu (mode) dla danego modelu.
    """
    # 1. Normalizacja rÃ³l i przetwarzanie wiadomoÅ›ci
    #    - Zmieniamy niestandardowÄ… rolÄ™ 'developer' na 'system' dla zgodnoÅ›ci.
    #    - Rozdzielamy tekst i zaÅ‚Ä…czniki.
    messages = openai_data.get("messages", [])
    for msg in messages:
        if msg.get("role") == "developer":
            msg["role"] = "system"
            logger.info("Normalizacja roli wiadomoÅ›ci: zmieniono 'developer' na 'system'.")
            
    processed_messages = []
    for msg in messages:
        processed_msg = await _process_openai_message(msg.copy())
        processed_messages.append(processed_msg)

    # 2. Zastosowanie trybu Tavern (Tavern Mode)
    if CONFIG.get("tavern_mode_enabled"):
        system_prompts = [msg['content'] for msg in processed_messages if msg['role'] == 'system']
        other_messages = [msg for msg in processed_messages if msg['role'] != 'system']
        
        merged_system_prompt = "\n\n".join(system_prompts)
        final_messages = []
        
        if merged_system_prompt:
            # WiadomoÅ›ci systemowe nie powinny zawieraÄ‡ zaÅ‚Ä…cznikÃ³w
            final_messages.append({"role": "system", "content": merged_system_prompt, "attachments": []})
        
        final_messages.extend(other_messages)
        processed_messages = final_messages

    # 3. OkreÅ›lenie docelowego ID modelu
    model_name = openai_data.get("model", "claude-3-5-sonnet-20241022")
    model_info = MODEL_NAME_TO_ID_MAP.get(model_name, {})  # WaÅ¼ne: zawsze zapewniamy sÅ‚ownik
    
    target_model_id = None
    if model_info:
        target_model_id = model_info.get("id")
    else:
        logger.warning(f"Model '{model_name}' nie znaleziony w 'models.json'. Å»Ä…danie zostanie wysÅ‚ane bez specyficznego ID modelu.")

    if not target_model_id:
        logger.warning(f"Model '{model_name}' nie ma przypisanego ID w 'models.json'. Å»Ä…danie zostanie wysÅ‚ane bez ID modelu.")

    # 4. Budowa szablonÃ³w wiadomoÅ›ci
    message_templates = []
    for msg in processed_messages:
        message_templates.append({
            "role": msg["role"],
            "content": msg.get("content", ""),
            "attachments": msg.get("attachments", [])
        })
    
    # 4.5. Specjalne: jeÅ›li wiadomoÅ›Ä‡ uÅ¼ytkownika koÅ„czy siÄ™ na --bypass i zawiera obraz, budujemy faÅ‚szywÄ… odpowiedÅº asystenta
    if message_templates and message_templates[-1]["role"] == "user":
        last_msg = message_templates[-1]
        if last_msg["content"].strip().endswith("--bypass") and last_msg.get("attachments"):
            has_images = False
            for attachment in last_msg.get("attachments", []):
                if attachment.get("contentType", "").startswith("image/"):
                    has_images = True
                    break
            
            if has_images:
                logger.info("Wykryto znacznik --bypass oraz zaÅ‚Ä…cznik obrazu â€” konstruujÄ™ faÅ‚szywÄ… wiadomoÅ›Ä‡ asystenta.")
                
                # Usuwamy znacznik --bypass z treÅ›ci uÅ¼ytkownika
                last_msg["content"] = last_msg["content"].strip()[:-9].strip()
                
                # Tworzymy faÅ‚szywÄ… wiadomoÅ›Ä‡ asystenta z obrazami uÅ¼ytkownika
                fake_assistant_msg = {
                    "role": "assistant",
                    "content": "",  # pusta treÅ›Ä‡
                    "attachments": last_msg.get("attachments", []).copy()  # kopiujemy obrazy
                }
                
                # CzyÅ›cimy zaÅ‚Ä…czniki oryginalnej wiadomoÅ›ci uÅ¼ytkownika
                last_msg["attachments"] = []
                
                # Wstawiamy faÅ‚szywÄ… wiadomoÅ›Ä‡ asystenta przed uÅ¼ytkownikiem
                message_templates.insert(len(message_templates)-1, fake_assistant_msg)
                
                # JeÅ›li pierwsza wiadomoÅ›Ä‡ jest od asystenta, dodajemy faÅ‚szywÄ… wiadomoÅ›Ä‡ uÅ¼ytkownika na poczÄ…tek
                if message_templates[0]["role"] == "assistant":
                    logger.info("Wykryto, Å¼e pierwsza wiadomoÅ›Ä‡ jest od asystenta â€” dodajÄ™ faÅ‚szywÄ… wiadomoÅ›Ä‡ uÅ¼ytkownika.")
                    fake_user_msg = {
                        "role": "user",
                        "content": "Hi",
                        "attachments": []
                    }
                    message_templates.insert(0, fake_user_msg)

    # 5. Zastosowanie trybu Bypass (tylko dla modeli tekstowych)
    model_type = model_info.get("type", "text")
    if CONFIG.get("bypass_enabled") and model_type == "text":
        # Tryb bypass zawsze wstawia pustÄ… wiadomoÅ›Ä‡ uÅ¼ytkownika z participantPosition 'a'
        logger.info("Tryb Bypass jest wÅ‚Ä…czony â€” wstrzykujÄ™ pustÄ… wiadomoÅ›Ä‡ uÅ¼ytkownika.")
        message_templates.append({"role": "user", "content": " ", "participantPosition": "a", "attachments": []})

    # 6. Ustawienie Participant Position
    # Najpierw sprawdzamy nadpisanie trybu, inaczej uÅ¼ywamy globalnej konfiguracji
    mode = mode_override or CONFIG.get("id_updater_last_mode", "direct_chat")
    target_participant = battle_target_override or CONFIG.get("id_updater_battle_target", "A")
    target_participant = target_participant.lower()  # wymuszamy maÅ‚e litery

    logger.info(f"Ustawiam Participant Positions wedÅ‚ug trybu '{mode}' (cel: {target_participant if mode == 'battle' else 'N/A'}).")

    for msg in message_templates:
        if msg['role'] == 'system':
            if mode == 'battle':
                # W trybie Battle: system i wybrany asystent sÄ… po tej samej stronie (A -> 'a', B -> 'b')
                msg['participantPosition'] = target_participant
            else:
                # DirectChat: system zawsze 'b'
                msg['participantPosition'] = 'b'
        elif mode == 'battle':
            # W trybie Battle, pozostaÅ‚e wiadomoÅ›ci uÅ¼ywajÄ… wybranego participant
            msg['participantPosition'] = target_participant
        else:  # DirectChat
            # DirectChat: pozostaÅ‚e wiadomoÅ›ci uÅ¼ywajÄ… domyÅ›lnie 'a'
            msg['participantPosition'] = 'a'

    return {
        "message_templates": message_templates,
        "target_model_id": target_model_id,
        "session_id": session_id,
        "message_id": message_id
    }

# --- Pomocnicze formatowanie zgodne z OpenAI (bezpieczne JSON) ---
def format_openai_chunk(content: str, model: str, request_id: str) -> str:
    """Formatuje pojedynczy fragment strumieniowy zgodnie z formatem OpenAI SSE."""
    chunk = {
        "id": request_id, "object": "chat.completion.chunk",
        "created": int(time.time()), "model": model,
        "choices": [{"index": 0, "delta": {"content": content}, "finish_reason": None}]
    }
    return f"data: {json.dumps(chunk, ensure_ascii=False)}\n\n"

def format_openai_finish_chunk(model: str, request_id: str, reason: str = 'stop') -> str:
    """Formatuje koÅ„cowy fragment strumieniowy zgodny z OpenAI."""
    chunk = {
        "id": request_id, "object": "chat.completion.chunk",
        "created": int(time.time()), "model": model,
        "choices": [{"index": 0, "delta": {}, "finish_reason": reason}]
    }
    return f"data: {json.dumps(chunk, ensure_ascii=False)}\n\ndata: [DONE]\n\n"

def format_openai_error_chunk(error_message: str, model: str, request_id: str) -> str:
    """Formatuje fragment bÅ‚Ä™du zgodny z OpenAI SSE."""
    content = f"\n\n[LMArena Bridge Error]: {error_message}"
    return format_openai_chunk(content, model, request_id)

def format_openai_non_stream_response(content: str, model: str, request_id: str, reason: str = 'stop') -> dict:
    """Buduje zgodne z OpenAI kompletne (nie-strumieniowe) ciaÅ‚o odpowiedzi."""
    return {
        "id": request_id,
        "object": "chat.completion",
        "created": int(time.time()),
        "model": model,
        "choices": [{
            "index": 0,
            "message": {"role": "assistant", "content": content},
            "finish_reason": reason,
        }],
        "usage": {
            "prompt_tokens": 0,
            "completion_tokens": len(content) // 4,
            "total_tokens": len(content) // 4,
        },
    }

async def _process_lmarena_stream(request_id: str):
    """
    GÅ‚Ã³wny generator wewnÄ™trzny: przetwarza surowy strumieÅ„ z przeglÄ…darki i emituje zdarzenia.
    Typy zdarzeÅ„: ('content', str), ('finish', str), ('error', str)
    """
    global IS_REFRESHING_FOR_VERIFICATION
    queue = response_channels.get(request_id)
    if not queue:
        logger.error(f"PROCESSOR [ID: {request_id[:8]}]: Nie znaleziono kanaÅ‚u odpowiedzi.")
        yield 'error', 'BÅ‚Ä…d wewnÄ™trzny serwera: nie znaleziono kanaÅ‚u odpowiedzi.'
        return

    buffer = ""
    timeout = CONFIG.get("stream_response_timeout_seconds",360)
    text_pattern = re.compile(r'[ab]0:"((?:\\.|[^"\\])*)"')
    # Nowe: wzorzec do dopasowania i wyciÄ…gniÄ™cia URLi obrazÃ³w
    image_pattern = re.compile(r'[ab]2:(\[.*?\])')
    finish_pattern = re.compile(r'[ab]d:(\{.*?"finishReason".*?\})')
    error_pattern = re.compile(r'(\{\s*"error".*?\})', re.DOTALL)
    cloudflare_patterns = [r'<title>Just a moment...</title>', r'Enable JavaScript and cookies to continue']
    
    has_yielded_content = False  # Flaga, czy wygenerowano juÅ¼ treÅ›Ä‡

    try:
        while True:
            try:
                raw_data = await asyncio.wait_for(queue.get(), timeout=timeout)
            except asyncio.TimeoutError:
                logger.warning(f"PROCESSOR [ID: {request_id[:8]}]: Oczekiwanie na dane z przeglÄ…darki przekroczyÅ‚o limit ({timeout}s).")
                yield 'error', f'Przekroczono limit oczekiwania na odpowiedÅº po {timeout} sekundach.'
                return

            # --- ObsÅ‚uga weryfikacji Cloudflare ---
            def handle_cloudflare_verification():
                global IS_REFRESHING_FOR_VERIFICATION
                if not IS_REFRESHING_FOR_VERIFICATION:
                    logger.warning(f"PROCESSOR [ID: {request_id[:8]}]: Wykryto weryfikacjÄ™ CAPTCHA â€” wysyÅ‚am polecenie odÅ›wieÅ¼enia.")
                    IS_REFRESHING_FOR_VERIFICATION = True
                    if browser_ws:
                        asyncio.create_task(browser_ws.send_text(json.dumps({"command": "refresh"}, ensure_ascii=False)))
                    return "Wykryto weryfikacjÄ™ CAPTCHA. WysÅ‚ano polecenie odÅ›wieÅ¼enia przeglÄ…darki â€” sprÃ³buj ponownie za kilka sekund."
                else:
                    logger.info(f"PROCESSOR [ID: {request_id[:8]}]: Weryfikacja CAPTCHA juÅ¼ trwa â€” oczekujÄ™ na zakoÅ„czenie.")
                    return "Trwa oczekiwanie na ukoÅ„czenie weryfikacji CAPTCHA..."

            # 1. Sprawdzamy, czy otrzymaliÅ›my bezpoÅ›redni bÅ‚Ä…d z WebSocket
            if isinstance(raw_data, dict) and 'error' in raw_data:
                error_msg = raw_data.get('error', 'Nieznany bÅ‚Ä…d przeglÄ…darki')
                if isinstance(error_msg, str):
                    if '413' in error_msg or 'too large' in error_msg.lower():
                        friendly_error_msg = "PrzesyÅ‚anie nie powiodÅ‚o siÄ™: zaÅ‚Ä…cznik przekracza limit rozmiaru serwera LMArena (zwykle okoÅ‚o 5MB). SprÃ³buj zmniejszyÄ‡ plik lub przesÅ‚aÄ‡ mniejszy plik."
                        logger.warning(f"PROCESSOR [ID: {request_id[:8]}]: Wykryto bÅ‚Ä…d przekroczenia rozmiaru (413).")
                        yield 'error', friendly_error_msg
                        return
                    if any(re.search(p, error_msg, re.IGNORECASE) for p in cloudflare_patterns):
                        yield 'error', handle_cloudflare_verification()
                        return
                yield 'error', error_msg
                return

            # 2. Sprawdzamy sygnaÅ‚ [DONE]
            if raw_data == "[DONE]":
                # Reset stanu przeniesiono do websocket_endpoint, aby byÄ‡ pewnym, Å¼e przy ponownym poÅ‚Ä…czeniu stan zostanie zresetowany
                if has_yielded_content and IS_REFRESHING_FOR_VERIFICATION:
                     logger.info(f"PROCESSOR [ID: {request_id[:8]}]: Å»Ä…danie zakoÅ„czone pomyÅ›lnie; stan weryfikacji zostanie zresetowany przy nastÄ™pnym poÅ‚Ä…czeniu.")
                break

            # 3. Doklejamy do bufora i analizujemy
            buffer += "".join(str(item) for item in raw_data) if isinstance(raw_data, list) else raw_data

            if any(re.search(p, buffer, re.IGNORECASE) for p in cloudflare_patterns):
                yield 'error', handle_cloudflare_verification()
                return
            
            if (error_match := error_pattern.search(buffer)):
                try:
                    error_json = json.loads(error_match.group(1))
                    yield 'error', error_json.get("error", "Nieznany bÅ‚Ä…d z LMArena")
                    return
                except json.JSONDecodeError:
                    pass

            # Najpierw obsÅ‚ugujemy treÅ›Ä‡ tekstowÄ…
            while (match := text_pattern.search(buffer)):
                try:
                    text_content = json.loads(f'"{match.group(1)}"')
                    if text_content:
                        has_yielded_content = True
                        yield 'content', text_content
                except (ValueError, json.JSONDecodeError):
                    pass
                buffer = buffer[match.end():]

            # Nowe: obsÅ‚uga zawartoÅ›ci obrazÃ³w
            while (match := image_pattern.search(buffer)):
                try:
                    image_data_list = json.loads(match.group(1))
                    if isinstance(image_data_list, list) and image_data_list:
                        image_info = image_data_list[0]
                        if image_info.get("type") == "image" and "image" in image_info:
                            # Opakowujemy URL w Markdown i emitujemy jako blok treÅ›ci
                            markdown_image = f"![Image]({image_info['image']})"
                            yield 'content', markdown_image
                except (json.JSONDecodeError, IndexError) as e:
                    logger.warning(f"BÅ‚Ä…d parsowania URL obrazu: {e}, bufor: {buffer[:150]}")
                buffer = buffer[match.end():]

            if (finish_match := finish_pattern.search(buffer)):
                try:
                    finish_data = json.loads(finish_match.group(1))
                    yield 'finish', finish_data.get("finishReason", "stop")
                except (json.JSONDecodeError, IndexError):
                    pass
                buffer = buffer[finish_match.end():]

    except asyncio.CancelledError:
        logger.info(f"PROCESSOR [ID: {request_id[:8]}]: Zadanie anulowane.")
    finally:
        if request_id in response_channels:
            del response_channels[request_id]
            logger.info(f"PROCESSOR [ID: {request_id[:8]}]: KanaÅ‚ odpowiedzi zostaÅ‚ posprzÄ…tany.")

async def stream_generator(request_id: str, model: str):
    """Formatuje wewnÄ™trzny strumieÅ„ zdarzeÅ„ do odpowiedzi SSE w stylu OpenAI."""
    response_id = f"chatcmpl-{uuid.uuid4()}"
    logger.info(f"STREAMER [ID: {request_id[:8]}]: Uruchomiono generator strumieniowy.")
    
    finish_reason_to_send = 'stop'  # DomyÅ›lny powÃ³d zakoÅ„czenia

    async for event_type, data in _process_lmarena_stream(request_id):
        if event_type == 'content':
            yield format_openai_chunk(data, model, response_id)
        elif event_type == 'finish':
            # ZapamiÄ™tujemy powÃ³d zakoÅ„czenia, ale nie koÅ„czymy natychmiast â€” czekamy na [DONE]
            finish_reason_to_send = data
            if data == 'content-filter':
                warning_msg = "\n\nOdpowiedÅº zostaÅ‚a przerwana â€” moÅ¼liwe przekroczenie limitu kontekstu lub wewnÄ™trzne filtrowanie modelu."
                yield format_openai_chunk(warning_msg, model, response_id)
        elif event_type == 'error':
            logger.error(f"STREAMER [ID: {request_id[:8]}]: W strumieniu wystÄ…piÅ‚ bÅ‚Ä…d: {data}")
            yield format_openai_error_chunk(str(data), model, response_id)
            yield format_openai_finish_chunk(model, response_id, reason='stop')
            return  # Przy bÅ‚Ä™dzie koÅ„czymy

    # Wykonujemy to tylko gdy _process_lmarena_stream zakoÅ„czy siÄ™ naturalnie (otrzymano [DONE])
    yield format_openai_finish_chunk(model, response_id, reason=finish_reason_to_send)
    logger.info(f"STREAMER [ID: {request_id[:8]}]: Generator strumieniowy zakoÅ„czyÅ‚ siÄ™ poprawnie.")

async def non_stream_response(request_id: str, model: str):
    """Agreguje wewnÄ™trzny strumieÅ„ i zwraca jednÄ… odpowiedÅº JSON zgodnÄ… z OpenAI."""
    response_id = f"chatcmpl-{uuid.uuid4()}"
    logger.info(f"NON-STREAM [ID: {request_id[:8]}]: Rozpoczynam przetwarzanie odpowiedzi nie-strumieniowej.")
    
    full_content = []
    finish_reason = "stop"
    
    async for event_type, data in _process_lmarena_stream(request_id):
        if event_type == 'content':
            full_content.append(data)
        elif event_type == 'finish':
            finish_reason = data
            if data == 'content-filter':
                full_content.append("\n\nOdpowiedÅº zostaÅ‚a przerwana â€” moÅ¼liwe przekroczenie limitu kontekstu lub wewnÄ™trzne filtrowanie modelu.")
            # Nie przerywamy, czekamy na [DONE], by uniknÄ…Ä‡ warunkÃ³w wyÅ›cigu
        elif event_type == 'error':
            logger.error(f"NON-STREAM [ID: {request_id[:8]}]: WystÄ…piÅ‚ bÅ‚Ä…d podczas przetwarzania: {data}")
            
            # Ustalanie statusu bÅ‚Ä™du spÃ³jnie dla stream / non-stream
            status_code = 413 if "przekracza limit rozmiaru" in str(data) or "zaÅ‚Ä…cznik przekracza" in str(data) else 500

            error_response = {
                "error": {
                    "message": f"[LMArena Bridge Error]: {data}",
                    "type": "bridge_error",
                    "code": "attachment_too_large" if status_code == 413 else "processing_error"
                }
            }
            return Response(content=json.dumps(error_response, ensure_ascii=False), status_code=status_code, media_type="application/json")

    final_content = "".join(full_content)
    response_data = format_openai_non_stream_response(final_content, model, response_id, reason=finish_reason)
    
    logger.info(f"NON-STREAM [ID: {request_id[:8]}]: Agregacja odpowiedzi zakoÅ„czona.")
    return Response(content=json.dumps(response_data, ensure_ascii=False), media_type="application/json")

# --- Punkt koÅ„cowy WebSocket ---
@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    """ObsÅ‚uguje poÅ‚Ä…czenie WebSocket od skryptu Tampermonkey."""
    global browser_ws, IS_REFRESHING_FOR_VERIFICATION
    await websocket.accept()
    if browser_ws is not None:
        logger.warning("Wykryto nowe poÅ‚Ä…czenie skryptu Tampermonkey â€” poprzednie poÅ‚Ä…czenie zostanie zastÄ…pione.")
    
    # KaÅ¼de nowe poÅ‚Ä…czenie oznacza zakoÅ„czenie (lub brak) weryfikacji CAPTCHA
    if IS_REFRESHING_FOR_VERIFICATION:
        logger.info("âœ… Nowe poÅ‚Ä…czenie WebSocket nawiÄ…zane â€” stan weryfikacji CAPTCHA zresetowany.")
        IS_REFRESHING_FOR_VERIFICATION = False
        
    logger.info("âœ… Skrypt Tampermonkey poÅ‚Ä…czony z WebSocket.")
    browser_ws = websocket
    try:
        while True:
            # Odbieramy wiadomoÅ›ci od skryptu Tampermonkey
            message_str = await websocket.receive_text()
            message = json.loads(message_str)
            
            request_id = message.get("request_id")
            data = message.get("data")

            if not request_id or data is None:
                logger.warning(f"Otrzymano od przeglÄ…darki nieprawidÅ‚owÄ… wiadomoÅ›Ä‡: {message}")
                continue

            # Umieszczamy odebrane dane w odpowiedniej kolejce odpowiedzi
            if request_id in response_channels:
                await response_channels[request_id].put(data)
            else:
                logger.warning(f"âš ï¸ Otrzymano odpowiedÅº dla nieznanego lub zamkniÄ™tego Å¼Ä…dania: {request_id}")

    except WebSocketDisconnect:
        logger.warning("âŒ Klient Tampermonkey rozÅ‚Ä…czyÅ‚ siÄ™.")
    except Exception as e:
        logger.error(f"Nieznany bÅ‚Ä…d podczas obsÅ‚ugi WebSocket: {e}", exc_info=True)
    finally:
        browser_ws = None
        # CzyÅ›cimy wszystkie oczekujÄ…ce kanaÅ‚y odpowiedzi, aby nie pozostawiÄ‡ wiszÄ…cych Å¼Ä…daÅ„
        for queue in response_channels.values():
            await queue.put({"error": "Browser disconnected during operation"})
        response_channels.clear()
        logger.info("PoÅ‚Ä…czenie WebSocket zostaÅ‚o posprzÄ…tane.")

# --- Zgodne z OpenAI endpointy API ---
@app.get("/v1/models")
async def get_models():
    """Zwraca listÄ™ modeli zgodnÄ… z OpenAI."""
    if not MODEL_NAME_TO_ID_MAP:
        return JSONResponse(
            status_code=404,
            content={"error": "Lista modeli jest pusta lub plik 'models.json' nie zostaÅ‚ znaleziony."}
        )
    
    return {
        "object": "list",
        "data": [
            {
                "id": model_name, 
                "object": "model",
                "created": int(time.time()),
                "owned_by": "LMArenaBridge"
            }
            for model_name in MODEL_NAME_TO_ID_MAP.keys()
        ],
    }

@app.post("/internal/request_model_update")
async def request_model_update():
    """
    Odbiera Å¼Ä…danie od model_updater.py i wysyÅ‚a polecenie przez WebSocket,
    aby skrypt Tampermonkey przesÅ‚aÅ‚ ÅºrÃ³dÅ‚o strony.
    """
    if not browser_ws:
        logger.warning("MODEL UPDATE: Otrzymano Å¼Ä…danie aktualizacji, ale brak poÅ‚Ä…czenia z przeglÄ…darkÄ….")
        raise HTTPException(status_code=503, detail="Klient przeglÄ…darki nie jest poÅ‚Ä…czony.")
    
    try:
        logger.info("MODEL UPDATE: Otrzymano Å¼Ä…danie aktualizacji â€” wysyÅ‚am polecenie przez WebSocket...")
        await browser_ws.send_text(json.dumps({"command": "send_page_source"}))
        logger.info("MODEL UPDATE: Polecenie 'send_page_source' zostaÅ‚o wysÅ‚ane.")
        return JSONResponse({"status": "success", "message": "Polecenie wysÅ‚ania ÅºrÃ³dÅ‚a strony zostaÅ‚o wysÅ‚ane."})
    except Exception as e:
        logger.error(f"MODEL UPDATE: BÅ‚Ä…d podczas wysyÅ‚ania polecenia: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="Nie udaÅ‚o siÄ™ wysÅ‚aÄ‡ polecenia przez WebSocket.")

@app.post("/internal/update_available_models")
async def update_available_models_endpoint(request: Request):
    """
    Odbiera HTML strony od skryptu Tampermonkey, wyciÄ…ga modele i aktualizuje available_models.json.
    """
    html_content = await request.body()
    if not html_content:
        logger.warning("Å»Ä…danie aktualizacji modeli nie zawieraÅ‚o treÅ›ci HTML.")
        return JSONResponse(
            status_code=400,
            content={"status": "error", "message": "Nie otrzymano treÅ›ci HTML."}
        )
    
    logger.info("Otrzymano HTML od skryptu Tampermonkey â€” rozpoczynam ekstrakcjÄ™ dostÄ™pnych modeli...")
    new_models_list = extract_models_from_html(html_content.decode('utf-8'))
    
    if new_models_list:
        save_available_models(new_models_list)
        return JSONResponse({"status": "success", "message": "Plik available_models.json zostaÅ‚ zaktualizowany."})
    else:
        logger.error("Nie udaÅ‚o siÄ™ wyodrÄ™bniÄ‡ danych modeli z dostarczonego HTML.")
        return JSONResponse(
            status_code=400,
            content={"status": "error", "message": "Nie moÅ¼na wyodrÄ™bniÄ‡ danych modeli z HTML."}
        )


@app.post("/v1/chat/completions")
async def chat_completions(request: Request):
    """
    ObsÅ‚uga Å¼Ä…daÅ„ chat/completions.
    Konwertuje format OpenAI -> LMArena, wysyÅ‚a przez WebSocket do skryptu Tampermonkey,
    a nastÄ™pnie zwraca wynik (stream lub non-stream).
    """
    global last_activity_time
    last_activity_time = datetime.now()  # Aktualizujemy czas aktywnoÅ›ci
    logger.info(f"Otrzymano Å¼Ä…danie API â€” czas aktywnoÅ›ci zaktualizowany: {last_activity_time.strftime('%Y-%m-%d %H:%M:%S')}")

    try:
        openai_req = await request.json()
    except json.JSONDecodeError:
        raise HTTPException(status_code=400, detail="NieprawidÅ‚owe ciaÅ‚o Å¼Ä…dania JSON")

    model_name = openai_req.get("model")
    model_info = MODEL_NAME_TO_ID_MAP.get(model_name, {})  # WaÅ¼ne: jeÅ›li brak modelu, otrzymujemy pusty sÅ‚ownik
    model_type = model_info.get("type", "text")  # DomyÅ›lnie text

    # --- Nowe: Logika rozpoznawania typu modelu ---
    if model_type == 'image':
        logger.info(f"Wykryto, Å¼e model '{model_name}' jest typu 'image' â€” bÄ™dzie obsÅ‚uÅ¼ony przez gÅ‚Ã³wny endpoint chat.")
        # Dla modeli obrazkowych ponownie uÅ¼ywamy gÅ‚Ã³wnej logiki, poniewaÅ¼ _process_lmarena_stream obsÅ‚uguje obrazy.
        pass  # Kontynuujemy wspÃ³lnÄ… obsÅ‚ugÄ™ chat
    # --- Koniec logiki generowania obrazÃ³w ---

    # JeÅ›li model nie jest obrazkowy, wykonujemy standardowÄ… logikÄ™ tekstowÄ…
    load_config()  # Wczytujemy aktualnÄ… konfiguracjÄ™ na Å¼ywo, by mieÄ‡ aktualne sessionId itd.
    # --- Weryfikacja API Key ---
    api_key = CONFIG.get("api_key")
    if api_key:
        auth_header = request.headers.get('Authorization')
        if not auth_header or not auth_header.startswith('Bearer '):
            raise HTTPException(
                status_code=401,
                detail="BrakujÄ…cy klucz API. Podaj nagÅ‚Ã³wek Authorization w formacie 'Bearer YOUR_KEY'."
            )
        
        provided_key = auth_header.split(' ')[1]
        if provided_key != api_key:
            raise HTTPException(
                status_code=401,
                detail="Podany klucz API jest nieprawidÅ‚owy."
            )

    # --- Wzmacniana kontrola poÅ‚Ä…czenia rozwiÄ…zujÄ…ca warunki wyÅ›cigu po weryfikacji CAPTCHA ---
    if IS_REFRESHING_FOR_VERIFICATION and not browser_ws:
        raise HTTPException(
            status_code=503,
            detail="Oczekiwanie na odÅ›wieÅ¼enie przeglÄ…darki w celu ukoÅ„czenia weryfikacji CAPTCHA â€” sprÃ³buj ponownie za kilka sekund."
        )

    if not browser_ws:
        raise HTTPException(
            status_code=503,
            detail="Klient Tampermonkey nie jest podÅ‚Ä…czony. Upewnij siÄ™, Å¼e strona LMArena jest otwarta i skrypt aktywny."
        )

    # --- Mapowanie model -> session/message ID ---
    session_id, message_id = None, None
    mode_override, battle_target_override = None, None

    if model_name and model_name in MODEL_ENDPOINT_MAP:
        mapping_entry = MODEL_ENDPOINT_MAP[model_name]
        selected_mapping = None

        if isinstance(mapping_entry, list) and mapping_entry:
            selected_mapping = random.choice(mapping_entry)
            logger.info(f"Dla modelu '{model_name}' wybrano losowo jedno z mapowaÅ„ ID.")
        elif isinstance(mapping_entry, dict):
            selected_mapping = mapping_entry
            logger.info(f"Dla modelu '{model_name}' znaleziono pojedyncze mapowanie endpointu (stary format).")
        
        if selected_mapping:
            session_id = selected_mapping.get("session_id")
            message_id = selected_mapping.get("message_id")
            # Pobieramy takÅ¼e informacje o trybie
            mode_override = selected_mapping.get("mode")  # moÅ¼e byÄ‡ None
            battle_target_override = selected_mapping.get("battle_target")  # moÅ¼e byÄ‡ None
            log_msg = f"Zostanie uÅ¼yte Session ID: ...{session_id[-6:] if session_id else 'N/A'}"
            if mode_override:
                log_msg += f" (tryb: {mode_override}"
                if mode_override == 'battle':
                    log_msg += f", cel: {battle_target_override or 'A'}"
                log_msg += ")"
            logger.info(log_msg)

    # JeÅ›li nadal brak session_id, stosujemy logikÄ™ globalnego fallbacku
    if not session_id:
        if CONFIG.get("use_default_ids_if_mapping_not_found", True):
            session_id = CONFIG.get("session_id")
            message_id = CONFIG.get("message_id")
            # Przy uÅ¼yciu globalnych ID nie nadpisujemy trybu â€” uÅ¼yjemy konfiguracji globalnej
            mode_override, battle_target_override = None, None
            logger.info(f"Model '{model_name}' nie miaÅ‚ mapowania â€” uÅ¼yto domyÅ›lnego Session ID: ...{session_id[-6:] if session_id else 'N/A'}")
        else:
            logger.error(f"Model '{model_name}' nie ma wpisu w 'model_endpoint_map.json' i wyÅ‚Ä…czono fallback do domyÅ›lnych ID.")
            raise HTTPException(
                status_code=400,
                detail=f"Model '{model_name}' nie ma skonfigurowanego indywidualnego ID sesji. Dodaj mapowanie w 'model_endpoint_map.json' lub wÅ‚Ä…cz 'use_default_ids_if_mapping_not_found' w 'config.jsonc'."
            )

    # --- Walidacja ostatecznych ID sesji ---
    if not session_id or not message_id or "YOUR_" in session_id or "YOUR_" in message_id:
        raise HTTPException(
            status_code=400,
            detail="Ostateczne session_id lub message_id sÄ… nieprawidÅ‚owe. SprawdÅº konfiguracjÄ™ w 'model_endpoint_map.json' i 'config.jsonc' lub uruchom `id_updater.py`."
        )

    if not model_name or model_name not in MODEL_NAME_TO_ID_MAP:
        logger.warning(f"Å»Ä…dany model '{model_name}' nie wystÄ™puje w models.json â€” zostanie uÅ¼yty domyÅ›lny model.")

    request_id = str(uuid.uuid4())
    response_channels[request_id] = asyncio.Queue()
    logger.info(f"API CALL [ID: {request_id[:8]}]: Utworzono kanaÅ‚ odpowiedzi.")

    try:
        # --- Preprocessing zaÅ‚Ä…cznikÃ³w (w tym upload do file bed) ---
        # Przetwarzamy wszystkie zaÅ‚Ä…czniki przed komunikacjÄ… z przeglÄ…darkÄ…; jeÅ›li wystÄ…pi bÅ‚Ä…d, od razu zwracamy bÅ‚Ä…d.
        messages_to_process = openai_req.get("messages", [])
        for message in messages_to_process:
            content = message.get("content")
            if isinstance(content, list):
                for i, part in enumerate(content):
                    if part.get("type") == "image_url" and CONFIG.get("file_bed_enabled"):
                        image_url_data = part.get("image_url", {})
                        base64_url = image_url_data.get("url")
                        original_filename = image_url_data.get("detail")
                        
                        if not (base64_url and base64_url.startswith("data:")):
                            raise ValueError(f"NieprawidÅ‚owy format danych obrazka: {base64_url[:100] if base64_url else 'None'}")

                        upload_url = CONFIG.get("file_bed_upload_url")
                        if not upload_url:
                            raise ValueError("WÅ‚Ä…czono file bed, ale 'file_bed_upload_url' nie jest skonfigurowane.")
                        
                        # Naprawiamy ewentualne escape'owane ukoÅ›niki
                        upload_url = upload_url.replace('\\/', '/')

                        api_key = CONFIG.get("file_bed_api_key")
                        
                        # JeÅ›li brak nazwy pliku, generujemy jÄ… na podstawie MIME z base64
                        if not original_filename:
                            try:
                                content_type = base64_url.split(';')[0].split(':')[1]
                                
                                # Prefiks na podstawie typu MIME
                                main_type = content_type.split('/')[0] if '/' in content_type else 'file'
                                prefix = main_type if main_type in ['image', 'audio', 'video', 'application', 'text'] else 'file'
                                
                                # PrÃ³bujemy uzyskaÄ‡ rozszerzenie z mimetypes
                                ext = mimetypes.guess_extension(content_type)
                                if ext:
                                    ext = ext.lstrip('.')
                                else:
                                    ext = 'bin'
                                
                                file_name = f"{prefix}_{uuid.uuid4()}.{ext}"
                            except Exception as e:
                                logger.warning(f"BÅ‚Ä…d parsowania MIME â€” uÅ¼ywam domyÅ›lnej nazwy pliku: {e}")
                                file_name = f"file_{uuid.uuid4()}.bin"
                        else:
                            file_name = original_filename
                        
                        logger.info(f"Preprocessing file bed: wysyÅ‚am '{file_name}' (MIME: {base64_url.split(';')[0].split(':')[1] if base64_url.startswith('data:') else 'unknown'})...")
                        
                        uploaded_filename, error_message = await upload_to_file_bed(file_name, base64_url, upload_url, api_key)

                        if error_message:
                            raise IOError(f"BÅ‚Ä…d uploadu do file bed: {error_message}")
                        
                        # Zgodnie z konwencjÄ… konfiguracji budujemy finalny URL do pliku
                        url_prefix = upload_url.rsplit('/', 1)[0]
                        final_url = f"{url_prefix}/uploads/{uploaded_filename}"
                        
                        part["image_url"]["url"] = final_url
                        logger.info(f"URL zaÅ‚Ä…cznika zostaÅ‚ zastÄ…piony wartoÅ›ciÄ…: {final_url}")

        # 1. Konwersja Å¼Ä…dania (w tej chwili nie powinno byÄ‡ juÅ¼ zaÅ‚Ä…cznikÃ³w wymagajÄ…cych uploadu)
        lmarena_payload = await convert_openai_to_lmarena_payload(
            openai_req,
            session_id,
            message_id,
            mode_override=mode_override,
            battle_target_override=battle_target_override
        )
        
        # Dodatkowo informujemy skrypt Tampermonkey, jeÅ›li Å¼Ä…danie dotyczy obrazu
        if model_type == 'image':
            lmarena_payload['is_image_request'] = True
        
        # 2. Przygotowanie wiadomoÅ›ci do wysÅ‚ania do przeglÄ…darki
        message_to_browser = {
            "request_id": request_id,
            "payload": lmarena_payload
        }
        
        # 3. WysyÅ‚ka przez WebSocket
        logger.info(f"API CALL [ID: {request_id[:8]}]: WysyÅ‚am Å‚adunek do skryptu Tampermonkey przez WebSocket.")
        await browser_ws.send_text(json.dumps(message_to_browser))

        # 4. Zwracamy strumieniowo lub jako non-stream w zaleÅ¼noÅ›ci od parametru stream
        is_stream = openai_req.get("stream", False)

        if is_stream:
            # Zwracamy odpowiedÅº strumieniowÄ…
            return StreamingResponse(
                stream_generator(request_id, model_name or "default_model"),
                media_type="text/event-stream"
            )
        else:
            # Zwracamy odpowiedÅº nie-strumieniowÄ…
            return await non_stream_response(request_id, model_name or "default_model")
    except (ValueError, IOError) as e:
        # BÅ‚Ä™dy zwiÄ…zane z przetwarzaniem zaÅ‚Ä…cznikÃ³w
        logger.error(f"API CALL [ID: {request_id[:8]}]: BÅ‚Ä…d podczas preprocesu zaÅ‚Ä…cznikÃ³w: {e}")
        if request_id in response_channels:
            del response_channels[request_id]
        # Zwracamy poprawnie sformatowany bÅ‚Ä…d JSON
        return JSONResponse(
            status_code=500,
            content={"error": {"message": f"[LMArena Bridge Error] BÅ‚Ä…d przetwarzania zaÅ‚Ä…cznikÃ³w: {e}", "type": "attachment_error"}}
        )
    except Exception as e:
        # Inne nieoczekiwane bÅ‚Ä™dy
        if request_id in response_channels:
            del response_channels[request_id]
        logger.error(f"API CALL [ID: {request_id[:8]}]: Krytyczny bÅ‚Ä…d podczas obsÅ‚ugi Å¼Ä…dania: {e}", exc_info=True)
        # Zwracamy takÅ¼e poprawnie sformatowany bÅ‚Ä…d JSON
        return JSONResponse(
            status_code=500,
            content={"error": {"message": str(e), "type": "internal_server_error"}}
        )

# --- Endpoints wewnÄ™trzne ---
@app.post("/internal/start_id_capture")
async def start_id_capture():
    """
    Odbiera Å¼Ä…danie od id_updater.py i wysyÅ‚a przez WebSocket polecenie
    aktywacji trybu przechwytywania ID w skrypcie Tampermonkey.
    """
    if not browser_ws:
        logger.warning("ID CAPTURE: Otrzymano Å¼Ä…danie aktywacji, ale brak poÅ‚Ä…czenia z przeglÄ…darkÄ….")
        raise HTTPException(status_code=503, detail="Klient przeglÄ…darki nie jest poÅ‚Ä…czony.")
    
    try:
        logger.info("ID CAPTURE: Otrzymano proÅ›bÄ™ o aktywacjÄ™ â€” wysyÅ‚am polecenie przez WebSocket...")
        await browser_ws.send_text(json.dumps({"command": "activate_id_capture"}))
        logger.info("ID CAPTURE: Polecenie aktywacji zostaÅ‚o wysÅ‚ane.")
        return JSONResponse({"status": "success", "message": "Polecenie aktywacji zostaÅ‚o wysÅ‚ane."})
    except Exception as e:
        logger.error(f"ID CAPTURE: BÅ‚Ä…d podczas wysyÅ‚ania polecenia aktywacji: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="Nie udaÅ‚o siÄ™ wysÅ‚aÄ‡ polecenia przez WebSocket.")


# --- Punkt wejÅ›cia programu ---
if __name__ == "__main__":
    # Sugerowane: wczytywaÄ‡ port z config.jsonc; tutaj tymczasowo zakodowany
    api_port = 5102
    logger.info(f"ðŸš€ Serwer API LMArena Bridge v2.0 uruchamia siÄ™...")
    logger.info(f"   - Adres nasÅ‚uchu: http://127.0.0.1:{api_port}")
    logger.info(f"   - Punkt WebSocket: ws://127.0.0.1:{api_port}/ws")
    
    uvicorn.run(app, host="0.0.0.0", port=api_port)