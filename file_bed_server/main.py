# file_bed_server/main.py
import base64
import os
import uuid
import time
from datetime import datetime, timedelta
from contextlib import asynccontextmanager
from fastapi import FastAPI, HTTPException, Request
from fastapi.responses import JSONResponse
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel
import logging
from apscheduler.schedulers.background import BackgroundScheduler

# --- Podstawowa konfiguracja ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# --- Konfiguracja Å›cieÅ¼ek ---
# Umieszczamy katalog uploadÃ³w obok tego pliku main.py
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
UPLOAD_DIR = os.path.join(BASE_DIR, "uploads")
API_KEY = "your_secret_api_key"  # Prosty klucz uwierzytelniajÄ…cy
CLEANUP_INTERVAL_MINUTES = 1  # CzÄ™stotliwoÅ›Ä‡ zadania czyszczÄ…cego (minuty)
FILE_MAX_AGE_MINUTES = 10  # Maksymalny wiek pliku do przechowania (minuty)

# --- Funkcja czyszczÄ…ca stare pliki ---
def cleanup_old_files():
    """Przechodzi przez katalog uploadÃ³w i usuwa pliki starsze niÅ¼ zadany czas."""
    now = time.time()
    cutoff = now - (FILE_MAX_AGE_MINUTES * 60)
    
    logger.info(f"Uruchamiam zadanie czyszczenia â€” usuwam pliki starsze niÅ¼ {datetime.fromtimestamp(cutoff).strftime('%Y-%m-%d %H:%M:%S')}...")
    
    deleted_count = 0
    try:
        for filename in os.listdir(UPLOAD_DIR):
            file_path = os.path.join(UPLOAD_DIR, filename)
            if os.path.isfile(file_path):
                try:
                    file_mtime = os.path.getmtime(file_path)
                    if file_mtime < cutoff:
                        os.remove(file_path)
                        logger.info(f"UsuniÄ™to przeterminowany plik: {filename}")
                        deleted_count += 1
                except OSError as e:
                    logger.error(f"BÅ‚Ä…d podczas usuwania pliku '{file_path}': {e}")
    except Exception as e:
        logger.error(f"Nieoczekiwany bÅ‚Ä…d podczas czyszczenia starych plikÃ³w: {e}", exc_info=True)

    if deleted_count > 0:
        logger.info(f"Zadanie czyszczenia zakoÅ„czone â€” usuniÄ™to {deleted_count} plik(Ã³w).")
    else:
        logger.info("Zadanie czyszczenia zakoÅ„czone â€” brak plikÃ³w do usuniÄ™cia.")


# --- FastAPI lifecycle ---
scheduler = BackgroundScheduler(timezone="UTC")

@asynccontextmanager
async def lifespan(app: FastAPI):
    """Uruchamiane przy starcie serwera â€” startuje zadanie w tle; przy zamkniÄ™ciu zatrzymuje je."""
    # Uruchamiamy scheduler i dodajemy zadanie czyszczenia
    scheduler.add_job(cleanup_old_files, 'interval', minutes=CLEANUP_INTERVAL_MINUTES)
    scheduler.start()
    logger.info(f"Zadanie czyszczenia plikÃ³w uruchomione â€” bÄ™dzie uruchamiane co {CLEANUP_INTERVAL_MINUTES} minut.")
    yield
    # WyÅ‚Ä…czamy scheduler przy zamkniÄ™ciu
    scheduler.shutdown()
    logger.info("Zadanie czyszczenia plikÃ³w zostaÅ‚o zatrzymane.")


app = FastAPI(lifespan=lifespan)

# --- Upewnij siÄ™, Å¼e katalog upload istnieje ---
if not os.path.exists(UPLOAD_DIR):
    os.makedirs(UPLOAD_DIR)
    logger.info(f"Katalog uploadÃ³w '{UPLOAD_DIR}' zostaÅ‚ utworzony.")

# --- Montujemy statyczne pliki, aby udostÄ™pniaÄ‡ uploady ---
app.mount(f"/uploads", StaticFiles(directory=UPLOAD_DIR), name="uploads")

# --- Model Pydantic ---
class UploadRequest(BaseModel):
    file_name: str
    file_data: str  # odbiera kompletny Base64 data URI
    api_key: str | None = None

# --- Endpointy API ---
@app.post("/upload")
async def upload_file(request: UploadRequest, http_request: Request):
    """
    Przyjmuje plik zakodowany w base64, zapisuje go i zwraca dostÄ™pny URL.
    """
    # Prosta weryfikacja klucza API
    if API_KEY and request.api_key != API_KEY:
        raise HTTPException(status_code=401, detail="NieprawidÅ‚owy klucz API")

    try:
        # 1. Rozdzielenie nagÅ‚Ã³wka i danych base64
        header, encoded_data = request.file_data.split(',', 1)
        
        # 2. Dekodowanie base64
        file_data = base64.b64decode(encoded_data)
        
        # 3. Generowanie unikalnej nazwy pliku, aby uniknÄ…Ä‡ konfliktÃ³w
        file_extension = os.path.splitext(request.file_name)[1]
        if not file_extension:
            # PrÃ³ba wywnioskowania rozszerzenia z typu MIME w nagÅ‚Ã³wku
            import mimetypes
            mime_type = header.split(';')[0].split(':')[1]
            guessed_extension = mimetypes.guess_extension(mime_type)
            file_extension = guessed_extension if guessed_extension else '.bin'

        unique_filename = f"{uuid.uuid4()}{file_extension}"
        file_path = os.path.join(UPLOAD_DIR, unique_filename)

        # 4. Zapis pliku
        with open(file_path, "wb") as f:
            f.write(file_data)
        
        # 5. Zwracamy sukces i nazwÄ™ pliku
        logger.info(f"Plik '{request.file_name}' zostaÅ‚ zapisany jako '{unique_filename}'.")
        
        return JSONResponse(
            status_code=200,
            content={"success": True, "filename": unique_filename}
        )

    except (ValueError, IndexError) as e:
        logger.error(f"BÅ‚Ä…d parsowania base64: {e}")
        raise HTTPException(status_code=400, detail=f"NieprawidÅ‚owy format base64 data URI: {e}")
    except Exception as e:
        logger.error(f"Nieznany bÅ‚Ä…d podczas obsÅ‚ugi uploadu: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"BÅ‚Ä…d wewnÄ™trzny serwera: {e}")

@app.get("/")
def read_root():
    return {"message": "Serwer przechowywania plikÃ³w LMArena Bridge dziaÅ‚a."}

# --- Punkt wejÅ›cia programu ---
if __name__ == "__main__":
    import uvicorn
    logger.info("ðŸš€ Serwer file bed uruchamia siÄ™...")
    logger.info("   - Adres nasÅ‚uchu: http://127.0.0.1:5180")
    logger.info(f"   - Endpoint upload: http://127.0.0.1:5180/upload")
    logger.info(f"   - ÅšcieÅ¼ka do plikÃ³w: /uploads")
    uvicorn.run(app, host="0.0.0.0", port=5180)